log4j.rootLogger = INFO,console,sparkLogs
#log4j.appLogger = INFO,appLogs

log4j.appender.console = org.apache.log4j.ConsoleAppender
log4j.appender.console.layout = org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern = %d{yy/MM/dd HH:mm:ss} %p %c: %m%n

log4j.appender.sparkLogs=org.apache.log4j.DailyRollingFileAppender
log4j.appender.sparkLogs.File=spark.log
log4j.appender.sparkLogs.DatePattern='.'yyyy-MM-dd
log4j.appender.sparkLogs.layout=org.apache.log4j.PatternLayout
log4j.appender.sparkLogs.layout.ConversionPattern=[%p] %d %c %M - %m%n

#log4j.appender.appLogs=org.apache.log4j.DailyRollingFileAppender
#log4j.appender.appLogs.File=spark.log
#log4j.appender.appLogs.DatePattern='.'yyyy-MM-dd
#log4j.appender.appLogs.layout=org.apache.log4j.PatternLayout
#log4j.appender.appLogs.layout.ConversionPattern=[%p] %d %c %M - %m%n

log4j.logger.spark.storage=INFO, sparkLogs
log4j.additivity.spark.storage=false
log4j.logger.spark.scheduler=INFO, sparkLogs
log4j.additivity.spark.scheduler=false
log4j.logger.spark.CacheTracker=INFO, sparkLogs
log4j.additivity.spark.CacheTracker=false
log4j.logger.spark.CacheTrackerActor=INFO, sparkLogs
log4j.additivity.spark.CacheTrackerActor=false
log4j.logger.spark.MapOutputTrackerActor=INFO, sparkLogs
log4j.additivity.spark.MapOutputTrackerActor=false
log4j.logger.spark.MapOutputTracker=INFO, sparkLogs
log4j.additivity.spark.MapOutputTracker=false

log4j.logger.org.spark_project.jetty = WARN

log4j.logger.org.apache.kafka.clients.consumer.internals.Fetcher=WARN
log4j.logger.org.apache.spark.streaming=WARN

log4j.logger.org.apache.spark.storage=WARN
log4j.logger.org.apache.spark.rdd=WARN

log4j.logger.org.apache.parquet = ERROR
log4j.logger.parquet = ERROR

log4j.logger.org.apache.hadoop.hive.metastore = ERROR
log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler = FATAL
log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry = ERROR